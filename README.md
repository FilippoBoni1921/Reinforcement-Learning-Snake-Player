The goal of the classic Snake videogame is to increase the length of the snake in order to cover the totality of the game board and finally win. The snake grows by eating fruits placed randomly on the board and avoiding decreasing its length by eating himself or by hitting the wall. The main challenge of the game is to manage the space of the board efficiently in order to reach the fruit without decreasing the length of the snake. This obstacle becomes more and more difficult to tackle with the growth of the snake. In this work we apply Deep Reinforcement Learning agents to the Snake videogame and study in which measure they are able to tackle the challenge just explained. In particular we study the performances of three among the most used Deep RL algorithms: PPO, DQN and A2C. These three algorithms are also compared to a not learning baseline which has been developed considering the environment representing the videogame.
